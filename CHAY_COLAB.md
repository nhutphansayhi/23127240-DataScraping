# HÆ°á»›ng Dáº«n Cháº¡y Code TrÃªn Google Colab

VÃ¬ mÃ¡y cÃ¡ nhÃ¢n khÃ´ng Ä‘á»§ máº¡nh nÃªn em cháº¡y trÃªn Colab cho nhanh.

## BÆ°á»›c 1: Má»Ÿ Colab
VÃ o trang: https://colab.research.google.com/

## BÆ°á»›c 2: Táº¡o Notebook má»›i vÃ  copy code dÆ°á»›i Ä‘Ã¢y

### Cell 1: Clone code tá»« GitHub vá»
```python
!git clone https://github.com/nhutphansayhi/23127240-DataScraping.git
%cd 23127240-DataScraping/src
```

### Cell 2: CÃ i thÆ° viá»‡n cáº§n thiáº¿t
```python
!pip install requests arxiv bibtexparser psutil feedparser
```

### Cell 3: Cháº¡y scraper

**Test vá»›i 55 papers (Ä‘á»ƒ xem bÃ¡o cÃ¡o á»Ÿ paper thá»© 50):**
```python
!python main.py --start-id 14685 --end-id 14739
```

**Hoáº·c cháº¡y luÃ´n cáº£ 5000 papers (máº¥t ~14-20 giá»):**
```python
!python main.py
```

## Xem káº¿t quáº£

### Cell 4: Xem thá»‘ng kÃª
```python
import json
with open('../23127240_data/scraping_stats.json') as f:
    data = json.load(f)
    print(json.dumps(data, indent=2))
```

### Cell 5: Xem Paper Details CSV
```python
import pandas as pd
df = pd.read_csv('../23127240_data/paper_details.csv')
print(df.head(20))
print(f"\nTotal papers: {len(df)}")
print(f"Success rate: {df['success'].mean()*100:.2f}%")
```

### Cell 6: Download Káº¿t Quáº£ (Zip All Data)
```python
!cd .. && zip -r 23127240_results.zip 23127240_data/
from google.colab import files
files.download('../23127240_results.zip')
```

## âš¡ LÆ°u Ã½ quan trá»ng:

1. **Chá»n Runtime tá»‘t hÆ¡n**: `Runtime > Change runtime type > T4 GPU` (miá»…n phÃ­ vÃ  nhanh)
2. **BÃ¡o cÃ¡o tá»± Ä‘á»™ng**: Code sáº½ in bÃ¡o cÃ¡o 15 metrics **Má»–I 50 PAPERS**
3. **Tá»± Ä‘á»™ng resume**: Náº¿u bá»‹ ngáº¯t giá»¯a chá»«ng, cháº¡y láº¡i Cell 3 - nÃ³ sáº½ tá»± skip papers Ä‘Ã£ scrape xong
4. **Thá»i gian**: 
   - Code dÃ¹ng batch scraper (6 luá»“ng) nÃªn **~8-10 giÃ¢y/paper**
   - 5000 papers = **~11-14 giá»** (Colab free giá»›i háº¡n 12h)
   - **NÃªn cháº¡y tá»«ng batch ~3-4 giá»:**
     ```python
     # Batch 1: ~1500 papers (~3-4h)
     !python main.py --start-id 14685 --end-id 16184
     
     # Batch 2: ~1500 papers (~3-4h) 
     !python main.py --start-id 16185 --end-id 17684
     
     # Batch 3: ~2000 papers cÃ²n láº¡i (~4-5h)
     !python main.py --start-id 17685 --end-id 844
     ```

## ğŸ“ VÃ­ Dá»¥ Batch Report Má»—i 50 Papers:

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘               BATCH REPORT: PAPER 50 / 250                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ I. DATA STATISTICS                                               â•‘
â•‘ ---------------------------------------------------------------- â•‘
â•‘ ğŸ“„ Papers scraped successfully     : 48                          â•‘
â•‘ âœ… Overall success rate            : 96.00%                      â•‘
â•‘ ğŸ“¦ Avg paper size (before)         : 156.4 KB                   â•‘
â•‘ ğŸ“¦ Avg paper size (after)          : 89.2 KB                    â•‘
â•‘ ğŸ“š Avg references per paper        : 24.5                        â•‘
â•‘ âœ… Reference metadata success      : 89.23%                      â•‘
â•‘                                                                  â•‘
â•‘ II. SCRAPER PERFORMANCE                                          â•‘
â•‘ ---------------------------------------------------------------- â•‘
â•‘ A. Running Time                                                  â•‘
â•‘ â±ï¸  Total wall time                : 8.5 min                     â•‘
â•‘ â±ï¸  Avg time per paper             : 10.2s                       â•‘
â•‘ â±ï¸  Total time per paper           : 10.2s                       â•‘
â•‘ ğŸ” Entry discovery time            : 0.15s                       â•‘
â•‘                                                                  â•‘
â•‘ B. Memory Footprint                                              â•‘
â•‘ ğŸ’¾ Maximum RAM used                : 256 MB                      â•‘
â•‘ ğŸ’¾ Maximum disk storage            : 8.9 MB                      â•‘
â•‘ ğŸ’¾ Final output storage            : 8.2 MB                      â•‘
â•‘ ğŸ’¾ Average RAM consumption         : 189 MB                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

## ğŸ¯ File Ná»™p BÃ i:

- `23127240.zip` - Source code (Ä‘Ã£ cÃ³ sáºµn trong repo)
- `23127240_results.zip` - Káº¿t quáº£ scrape (download tá»« Cell 6)
- Link GitHub: https://github.com/nhutphansayhi/23127240-DataScraping

---
**MSSV: 23127240**
